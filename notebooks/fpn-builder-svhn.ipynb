{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset\n",
    "Download nad unpack SVHN dataset to datasets/SVHN/[train|test] folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_detection.datasets.svhn.read_svhm_map import load_dataset\n",
    "\n",
    "train_raw_dataset, num_train_examples = load_dataset('datasets/SVHN/train')\n",
    "test_raw_dataset, num_test_examples = load_dataset('datasets/SVHN/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_examples, num_test_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable tensorflow duplicated logs\n",
    "from tensorflow.python.platform.tf_logging import _logger\n",
    "_logger.handlers.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model input and dataset parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "image_dim = 128\n",
    "batch_size = 8\n",
    "num_epochs = -1\n",
    "num_parallel_calls = 8\n",
    "num_test_steps = num_test_examples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_detection.datasets.datasets_ops import prepare_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = prepare_dataset(\n",
    "    dataset=train_raw_dataset, \n",
    "    augmentation_fn=None,\n",
    "    model_image_size=(image_dim, image_dim),\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=num_epochs,\n",
    "    shuffle_buffer_size=512,\n",
    "    prefetch_buffer_size=2,\n",
    "    num_parallel_calls=num_parallel_calls\n",
    ")\n",
    "\n",
    "test_dataset = prepare_dataset(\n",
    "    dataset=test_raw_dataset, \n",
    "    augmentation_fn=None,\n",
    "    model_image_size=(image_dim, image_dim),\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=num_epochs,\n",
    "    shuffle_buffer_size=None,\n",
    "    prefetch_buffer_size=2,\n",
    "    num_parallel_calls=num_parallel_calls\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_detection.backbones.mobilenetv2_customized as mobilenet\n",
    "import keras_detection.tasks.standard_tasks as standard_tasks\n",
    "import keras_detection.models.fpn_builder as fpn_builder\n",
    "from keras_detection.utils import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "backbone = mobilenet.MobileNetV2Backbone(\n",
    "    input_shape=[image_dim, image_dim, 3],\n",
    "    alpha=1.0, min_fm_size=10, weights='imagenet'\n",
    ")\n",
    "\n",
    "tasks = [\n",
    "    # predicts objectnes score for each anchor\n",
    "    standard_tasks.get_objectness_task(label_smoothing=0.02, obj_class=\"center_ignore_margin\"),\n",
    "    # predicts [height, with, y, x ] location of the box\n",
    "    standard_tasks.get_box_shape_task(\"box_shape\"),\n",
    "    # predicts [num_classes] for each anchor\n",
    "    standard_tasks.get_multiclass_task(num_classes, fl_gamma=0.0, label_smoothing=0, activation='softmax'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = fpn_builder.FPNBuilder(backbone = backbone, tasks = tasks)\n",
    "model = builder.build(batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_train_dataset = train_dataset.map(builder.get_build_training_targets_fn())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(iter(prepared_train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = \"fm16x16\"\n",
    "\n",
    "targets = [labels[n][..., :-1] for n in builder.get_outputs_names()]\n",
    "targets = builder.predictions_to_dict(targets, postprocess=True)\n",
    "\n",
    "idx = 6\n",
    "target=dict(\n",
    "    objectness=targets[f'{fm}/objectness'][idx],\n",
    "    boxes_shape_map=targets[f'{fm}/box_shape'][idx],\n",
    "    classes_map=targets[f'{fm}/classes'][idx],\n",
    ")\n",
    "\n",
    "render = plotting.draw_compares(    \n",
    "    target=target,\n",
    "    predicted=None,\n",
    "    all_targets=True,\n",
    "    draw_fns=[\n",
    "        plotting.draw_boxes, \n",
    "        plotting.draw_classes_map,\n",
    "        plotting.draw_objectness_map,\n",
    "        plotting.draw_classes_max_score_map,\n",
    "    ],\n",
    "    image=features['image'][idx] / 255,\n",
    "    score_threshold=0.2, \n",
    ")\n",
    "render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.005, beta_2=0.99)\n",
    "model.compile(optimizer, **builder.get_model_compile_args())\n",
    "model.fit(prepared_train_dataset, epochs=1, steps_per_epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_detection.models.utils as kd_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_utils.freeze_model_bn_layers(model, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_2=0.99)\n",
    "model.compile(optimizer, **builder.get_model_compile_args())\n",
    "model.fit(prepared_train_dataset, epochs=1, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_utils.freeze_model_bn_layers(model, trainable=True)\n",
    "model.save_weights(\"models/non-quantized-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"models/non-quantized-model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "builder.evaluate_model(model, test_dataset, num_test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_test_dataset = test_dataset.map(builder.get_build_training_targets_fn())\n",
    "dataset_iterator = iter(prepared_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(dataset_iterator)\n",
    "predictions = model.predict(features)\n",
    "predictions = builder.predictions_to_dict(predictions, postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.get_outputs_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = \"fm16x16\"\n",
    "targets = [labels[n][..., :-1] for n in builder.get_outputs_names()]\n",
    "targets = builder.predictions_to_dict(targets, postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "target=dict(\n",
    "    objectness=targets[f'{fm}/objectness'][idx],\n",
    "    boxes_shape_map=targets[f'{fm}/box_shape'][idx],\n",
    "    classes_map=targets[f'{fm}/classes'][idx],\n",
    ")\n",
    "\n",
    "predicted=dict(\n",
    "    objectness=predictions[f'{fm}/objectness'][idx],\n",
    "    boxes_shape_map=predictions[f'{fm}/box_shape'][idx],\n",
    "    classes_map=predictions[f'{fm}/classes'][idx],\n",
    ")\n",
    "\n",
    "render = plotting.draw_compares(    \n",
    "    target=target,\n",
    "    predicted=predicted,\n",
    "    draw_fns=[\n",
    "        plotting.draw_boxes, \n",
    "        plotting.draw_classes_map,\n",
    "        plotting.draw_objectness_map,\n",
    "        plotting.draw_classes_max_score_map,\n",
    "    ],\n",
    "    image=features['image'][idx] / 255,\n",
    "    score_threshold=0.2,\n",
    ")\n",
    "render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quantized_model = builder.build_quantized(\n",
    "    batch_size=None, \n",
    "    non_quantized_model_weights=\"models/non-quantized-model.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.evaluate_model(quantized_model, test_dataset, num_test_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_train_dataset = train_dataset.map(builder.get_build_training_targets_fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_utils.freeze_model_bn_layers(quantized_model, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_2=0.99)\n",
    "quantized_model.compile(optimizer, **builder.get_model_compile_args())\n",
    "quantized_model.fit(prepared_train_dataset, epochs=1, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_utils.freeze_model_bn_layers(quantized_model, trainable=True)\n",
    "quantized_model.save_weights(\"models/quantized-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exported_model, tflite_models_paths = builder.convert_to_tflite(\n",
    "    model, \n",
    "    save_path=\"models/quantized-model.tflite\", \n",
    "    export_batch_size = 1,\n",
    "    raw_dataset = test_raw_dataset,\n",
    "    num_dataset_samples = 16,\n",
    "    num_test_steps = 8,\n",
    "    merge_feature_maps=True,\n",
    "    postprocess_outputs=True,\n",
    "    convert_quantized_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create box-predictor from converted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "box_detector =  builder.as_box_detector(\"models/quantized-model.h5\", is_quantized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = box_detector.predict(features['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0].draw(image=features['image'][0].numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
