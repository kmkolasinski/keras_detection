{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmkolasinski/keras_detection/blob/master/notebooks/fpn_builder_random_rectangles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wMqSml3iQLi6",
    "outputId": "a5635e69-b361-43db-c075-f0a0bd4425f4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install -q --extra-index-url=https://test.pypi.org/simple/ tensorflow-model-optimization==0.3.0.dev6\n",
    "# ! pip install --upgrade git+https://github.com/kmkolasinski/keras_detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEPgqMM5QI7p"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras_detection.datasets.datasets_ops as datasets_ops\n",
    "import keras_detection.datasets.random_rectangles as random_rects\n",
    "from keras_detection import ImageData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6e7ck4eQI7x"
   },
   "outputs": [],
   "source": [
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdYpg3iVeL1Z"
   },
   "outputs": [],
   "source": [
    "# Run this if you see tensorflow duplicated logs\n",
    "from tensorflow.python.platform.tf_logging import _logger\n",
    "_logger.propagate = False\n",
    "if len(_logger.handlers) > 1:\n",
    "  _logger.handlers.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-LndecQ1gK"
   },
   "source": [
    "Random rectangles detection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "zbgK5q_UQI72",
    "outputId": "2e016370-d954-417f-9965-1feed16c6d76"
   },
   "outputs": [],
   "source": [
    "dataset = datasets_ops.from_numpy_generator(\n",
    "    random_rects.create_random_rectangles_dataset_generator(min_max_num_boxes=(5, 30), min_max_height=(0.05, 0.2), alpha=0.2)\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPB-A2kFQI76"
   },
   "outputs": [],
   "source": [
    "# Benchmark dataset sampling\n",
    "# %timeit next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "colab_type": "code",
    "id": "AcyESwb0QI7_",
    "outputId": "a1d87ad9-e00d-4ba5-8d81-84ac17b7d0bd"
   },
   "outputs": [],
   "source": [
    "image_data = ImageData.from_dict(next(iter(dataset)))\n",
    "image_data.draw_boxes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ZgNu-4YREM5"
   },
   "source": [
    "# Build dataset (batched) and FPN detection model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGmNgqmKQI8D"
   },
   "outputs": [],
   "source": [
    "import keras_detection.datasets.datasets_ops as datasets_ops\n",
    "\n",
    "def aug_fn(image_data: ImageData) -> ImageData:\n",
    "    image = tf.cast(image_data.features.image, tf.float32)\n",
    "    # example augmentation \n",
    "    image_shape = tf.shape(image)\n",
    "    image = image + tf.random.uniform(minval=-10.0, maxval=10.0, shape=image_shape)\n",
    "    return image_data.replace_image(image)\n",
    "\n",
    "\n",
    "image_dim = 224\n",
    "batch_size = 8\n",
    "shuffle_buffer_size = 1 # we don't have to shuffle random rectangles dataset\n",
    "num_classes = 9 # random rectangles have 9 classes\n",
    "num_parallel_calls = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiCo_MkkQI8H"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets_ops.prepare_dataset(\n",
    "    dataset,\n",
    "    model_image_size=(image_dim, image_dim),\n",
    "    augmentation_fn=aug_fn,\n",
    "    num_epochs=-1,\n",
    "    batch_size=batch_size ,\n",
    "    shuffle_buffer_size=shuffle_buffer_size,\n",
    "    prefetch_buffer_size=4,\n",
    "    num_parallel_calls=num_parallel_calls\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uKSDh_zcQI8L"
   },
   "outputs": [],
   "source": [
    "# %timeit next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OAFwignURQ_E"
   },
   "source": [
    "# Build model builder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2EPrlGcQI8P"
   },
   "outputs": [],
   "source": [
    "from keras_detection import FPNBuilder\n",
    "from keras_detection.tasks import standard_tasks\n",
    "from keras_detection.backbones import resnet\n",
    "import keras_detection.backbones.fpn as fpn\n",
    "from keras_detection.utils import plotting\n",
    "from keras_detection.heads import SingleConvPoolHeadFactory, SingleConvPoolHead\n",
    "\n",
    "num_filters = 128\n",
    "\n",
    "backbone = resnet.ResNetBackbone(\n",
    "    input_shape=(image_dim, image_dim, 3),\n",
    "    units_per_block=(1, 1, 1),\n",
    "    num_last_blocks=2, # number of feature pyramids, setting single feature map\n",
    ")\n",
    "\n",
    "backbone = fpn.FPNBackbone(\n",
    "    backbone, depth=num_filters, \n",
    "    num_first_blocks=1\n",
    ")\n",
    "\n",
    "\n",
    "faster_rcnn_tasks = [\n",
    "    standard_tasks.get_box_shape_task(\n",
    "        \"box_shape\",\n",
    "        num_filters=num_filters,\n",
    "        head_factory = SingleConvPoolHeadFactory(\n",
    "            num_outputs=4,\n",
    "            num_filters=num_filters,\n",
    "            activation=\"relu\",\n",
    "            htype=SingleConvPoolHead,\n",
    "        )\n",
    "    ),\n",
    "    standard_tasks.get_multiclass_task(\n",
    "        num_classes,\n",
    "        fl_gamma=0.0, label_smoothing=0, \n",
    "        activation='softmax', \n",
    "        head_factory = SingleConvPoolHeadFactory(\n",
    "            num_outputs=num_classes + 1,\n",
    "            num_filters=num_filters,\n",
    "            activation=\"softmax\",\n",
    "            htype=SingleConvPoolHead,\n",
    "        )\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_detection.models.faster_rcnn_builder import FasterRCNNBuilder\n",
    "faster_rcnn_builder = FasterRCNNBuilder(\n",
    "    backbone = backbone,\n",
    "    rpn_objectness_task = standard_tasks.get_objectness_task(label_smoothing=0.02, obj_class=\"center_ignore_margin\", quantizable=False),\n",
    "    rpn_box_shape_task = standard_tasks.get_box_shape_task(\"box_shape\", quantizable=False),\n",
    "    rcnn_tasks = faster_rcnn_tasks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn_model = faster_rcnn_builder.build(batch_size=batch_size, is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_train_dataset = faster_rcnn_builder.prepare_dataset(train_dataset)\n",
    "prepared_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn_model.input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn_model.output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(iter(prepared_train_dataset))\n",
    "features.keys(), labels.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn_model.predict(features).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faster_rcnn_model.summary()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_2=0.995)\n",
    "faster_rcnn_model.compile(optimizer, **faster_rcnn_builder.rpn.get_model_compile_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn_model.fit(prepared_train_dataset, epochs=1, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faster_rcnn_model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oFhLzFJrQI8e"
   },
   "source": [
    "## Prepare labels (targets) for objectness, box shape regression and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_targets(batch_data):\n",
    "    features, targets = builder.get_build_training_targets_fn()(batch_data)\n",
    "    _, rcnn_targets = rcnn_builder.get_build_training_targets_fn()(batch_data)\n",
    "    targets.update(rcnn_targets)\n",
    "    return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KKiRhn_bQI8g"
   },
   "outputs": [],
   "source": [
    "prepared_train_dataset = train_dataset.map(prepare_targets)\n",
    "# prepared_rcnn_train_dataset = train_dataset.map(rcnn_builder.get_build_training_targets_fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "GQQrXV5xQI8j",
    "outputId": "668b897a-741c-4126-f576-b3729b7430b8"
   },
   "outputs": [],
   "source": [
    "prepared_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y36jhHVaQI8m"
   },
   "outputs": [],
   "source": [
    "features, labels = next(iter(prepared_train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oN-Sy0eZRzsX"
   },
   "source": [
    "Validating targets: objectness, box prediction and class predictions heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "id": "dNuwcP4OQI8q",
    "outputId": "51068373-4ad4-4d23-f665-f42338c1a888"
   },
   "outputs": [],
   "source": [
    "fm = \"fm56x56\"\n",
    "\n",
    "targets = [labels[n][..., :-1] for n in builder.get_outputs_names()]\n",
    "targets = builder.predictions_to_dict(targets, postprocess=True)\n",
    "\n",
    "idx = 0\n",
    "target=dict(\n",
    "    objectness=targets[f'{fm}/objectness'][idx],\n",
    "    boxes_shape_map=targets[f'{fm}/box_shape'][idx],\n",
    "#     classes_map=targets[f'{fm}/classes'][idx],\n",
    ")\n",
    "\n",
    "render = plotting.draw_compares(    \n",
    "    target=target,\n",
    "    predicted=None,\n",
    "    all_targets=True,\n",
    "    draw_fns=[\n",
    "        plotting.draw_boxes, \n",
    "#         plotting.draw_classes_map,\n",
    "        plotting.draw_objectness_map,\n",
    "#         plotting.draw_classes_max_score_map,\n",
    "    ],\n",
    "    image=features['image'][idx] / 255,\n",
    "    score_threshold=0.2, \n",
    ")\n",
    "render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aU89KJG2R82K"
   },
   "source": [
    "# Train standard Keras model and export to TFLite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iterator = iter(prepared_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(dataset_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "*predictions, feature_map = model(features)\n",
    "predictions_raw = builder.predictions_to_dict(predictions, postprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_args = builder.get_model_compile_args()\n",
    "prediction_losses = compile_args[\"loss\"]\n",
    "loss_weights = compile_args['loss_weights']\n",
    "\n",
    "losses = []\n",
    "for key, loss_class in prediction_losses.items():\n",
    "    loss_class.per_anchor_loss = True\n",
    "    loss = loss_class.call(y_true=labels[key], y_pred=predictions_raw[key])\n",
    "    weight = loss_weights[key]\n",
    "    losses.append(loss * weight)\n",
    "    loss_class.per_anchor_loss = False\n",
    "    \n",
    "losses = tf.add_n(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_post = builder.predictions_to_dict(predictions, postprocess=True)\n",
    "box_shape_key = f'{fm}/box_shape'\n",
    "\n",
    "boxes = box_shape_target.target_builder.to_tf_boxes(predictions_post[box_shape_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras_detection.targets import feature_map_sampling as fm_sampling\n",
    "from keras_detection.layers.roi_align import ROIAlignLayer\n",
    "from keras_detection import LabelsFrame\n",
    "\n",
    "num_samples = 64\n",
    "crop_size = (32, 32)\n",
    "roi_align = ROIAlignLayer(crop_size=crop_size)\n",
    "\n",
    "indices = fm_sampling.scores_to_gather_indices(losses, num_samples)\n",
    "# fm_sampling.sample_feature_map(tf.expand_dims(losses, -1), indices)\n",
    "\n",
    "sampled_boxes = fm_sampling.sample_feature_map(boxes, indices)\n",
    "frame = LabelsFrame(\n",
    "    boxes=sampled_boxes, \n",
    "    num_rows=tf.constant([num_samples] * batch_size)\n",
    ")\n",
    "\n",
    "crops = roi_align([feature_map, frame])\n",
    "crops.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_targets = {}\n",
    "for key, target in labels.items():\n",
    "    target = fm_sampling.sample_feature_map(target, indices)\n",
    "    crops_targets[key] = tf.reshape(target, [batch_size * num_samples, -1])\n",
    "    \n",
    "crops_targets.keys(), target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crops_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn_outputs = rcnn_builder.build_heads_forward([crops])\n",
    "rcnn_predictions_raw = rcnn_builder.predictions_to_dict(rcnn_outputs, postprocess=False)\n",
    "rcnn_predictions_raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_args = rcnn_builder.get_model_compile_args()\n",
    "rcnn_prediction_losses = compile_args[\"loss\"]\n",
    "rcnn_loss_weights = compile_args['loss_weights']\n",
    "\n",
    "rcnn_losses = []\n",
    "for key, loss_class in rcnn_prediction_losses.items():\n",
    "    print(key)\n",
    "    old_key = key.replace(\"32\", \"56\")\n",
    "    y_true = crops_targets[old_key]\n",
    "    y_pred = rcnn_predictions_raw[key]\n",
    "    y_true = tf.expand_dims(tf.expand_dims(y_true, axis=1), axis=1)\n",
    "    y_pred = tf.expand_dims(tf.expand_dims(y_pred, axis=1), axis=1)\n",
    "    loss = loss_class.call(y_true=y_true, y_pred=y_pred)\n",
    "    weight = rcnn_loss_weights[key]\n",
    "    rcnn_losses.append(loss * weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hwwnj604QI8t"
   },
   "outputs": [],
   "source": [
    "import keras_detection.models.utils as kd_utils\n",
    "\n",
    "l2_reg_fn = kd_utils.get_l2_loss_fn(l2_reg=1e-5, model=model)\n",
    "model.add_loss(l2_reg_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "id": "IzLfJ2dsQI8x",
    "outputId": "9d95311b-c091-4e55-f984-e22584adcf5e"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_2=0.995)\n",
    "model.compile(optimizer, **builder.get_model_compile_args())\n",
    "model.fit(prepared_train_dataset, epochs=5, steps_per_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "id": "hejFTMypZwlH",
    "outputId": "41444a02-01ad-432b-a4c9-1a089dd8d506"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.0005, beta_2=0.995)\n",
    "model.compile(optimizer, **builder.get_model_compile_args())\n",
    "model.fit(prepared_train_dataset, epochs=5, steps_per_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "id": "tz0QbcTcgBc-",
    "outputId": "9ce8b69c-2b11-46b9-b8b1-b7aca8dd573c"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001, beta_2=0.995)\n",
    "model.compile(optimizer, **builder.get_model_compile_args())\n",
    "model.fit(prepared_train_dataset, epochs=5, steps_per_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0EpQLrIQI81"
   },
   "outputs": [],
   "source": [
    "!mkdir --parents models\n",
    "model.save_weights(\"models/non-quantized-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gHbMdIoTEdd"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"models/non-quantized-model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8x6WNeFS_Rv"
   },
   "source": [
    "## Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "TuCz3T8VS0Uf",
    "outputId": "4f7e7c4f-0df3-45dc-f34b-8e0c91af3f69"
   },
   "outputs": [],
   "source": [
    "def draw_predictions(model, features, labels, idx = 0, fm = \"fm28x28\", score_threshold = 0.5):\n",
    "  \n",
    "  predictions = model.predict(features)\n",
    "  predictions = builder.predictions_to_dict(predictions, postprocess=True)\n",
    "\n",
    "  \n",
    "  targets = [labels[n][..., :-1] for n in builder.get_outputs_names()]\n",
    "  targets = builder.predictions_to_dict(targets, postprocess=True)\n",
    "\n",
    "  target=dict(\n",
    "      objectness=targets[f'{fm}/objectness'][idx],\n",
    "      boxes_shape_map=targets[f'{fm}/box_shape'][idx],\n",
    "      classes_map=targets[f'{fm}/classes'][idx],\n",
    "  )\n",
    "\n",
    "  predicted=dict(\n",
    "      objectness=predictions[f'{fm}/objectness'][idx],\n",
    "      boxes_shape_map=predictions[f'{fm}/box_shape'][idx],\n",
    "      classes_map=predictions[f'{fm}/classes'][idx],\n",
    "  )\n",
    "\n",
    "  render = plotting.draw_compares(    \n",
    "      target=target,\n",
    "      predicted=predicted,\n",
    "      draw_fns=[\n",
    "          plotting.draw_boxes, \n",
    "          plotting.draw_classes_map,\n",
    "          plotting.draw_objectness_map,\n",
    "          plotting.draw_classes_max_score_map,\n",
    "      ],\n",
    "      image=features['image'][idx] / 255,\n",
    "      score_threshold=score_threshold,\n",
    "  )\n",
    "  return render\n",
    "\n",
    "\n",
    "features, labels = next(iter(prepared_train_dataset))\n",
    "draw_predictions(model, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ZBTnWiGUhyB"
   },
   "source": [
    "## Export model to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dqhxOzL1UD97",
    "outputId": "fab9c6b3-fcf2-4694-9fd2-5a0424b5372a"
   },
   "outputs": [],
   "source": [
    "# creates two versions of the model:  \n",
    "#  - models/non-quantized-model.tflite\n",
    "#  - models/non-quantized-model-quantized.tflite (for this representative dataset is used to accumulate stats)\n",
    "\n",
    "exported_model, tflite_models_paths = builder.convert_to_tflite(    \n",
    "    model, \n",
    "    save_path=\"models/non-quantized-model.tflite\", \n",
    "    export_batch_size = 1,\n",
    "    raw_dataset = dataset,  # dataset to the test the stats between (per image data)\n",
    "    num_dataset_samples = 64, # representative dataset number of samples\n",
    "    num_test_steps = 16, # number of images used to test output statistics\n",
    "    merge_feature_maps=True,  # merge FPN feature maps into single tensor of shape [1, num_anchors, num_outputs]\n",
    "    postprocess_outputs=True,  # apply post processing on head outputs e.g. decode box coordinates to [height, width, y_center, x_center]\n",
    "    convert_quantized_model=True # Use represenetative dataset to create integer quantized model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "0gZlzPKzU5j8",
    "outputId": "25933a86-5291-439d-b10e-d7b65566f2d4"
   },
   "outputs": [],
   "source": [
    "tflite_models_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z7dOoW5nWGqY"
   },
   "source": [
    "# Train Quantized model and export to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "PTkvupjoVcJB",
    "outputId": "c570ce0b-0c69-46cb-cdde-5a163bf0fd42"
   },
   "outputs": [],
   "source": [
    "quantized_model = builder.build_quantized(\n",
    "    batch_size=None, \n",
    "    non_quantized_model_weights=\"models/non-quantized-model.h5\" # initialize weight from previous model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "HgOJRXkzWMwQ",
    "outputId": "d1ef18c3-da60-460f-a50d-67ea74311057"
   },
   "outputs": [],
   "source": [
    "# heads are not quantized (they have quantizable = Fales)\n",
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NUDMIv_UWP9v",
    "outputId": "d0c77eff-c7a1-4eb5-e5d3-8ad1727060d8"
   },
   "outputs": [],
   "source": [
    "# check if resnet is quantized\n",
    "quantized_model.layers[2].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "colab_type": "code",
    "id": "iiJRnJDtbczP",
    "outputId": "8e20433a-b8c2-46bf-9726-6667683a9ff6"
   },
   "outputs": [],
   "source": [
    "# check first head\n",
    "quantized_model.layers[3].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "rT8X1NtiWbes",
    "outputId": "7f373b7f-2897-4f12-b8e4-674e4fe47d94"
   },
   "outputs": [],
   "source": [
    "# test metrics after quantization, they should be worse\n",
    "# we can evaluate on train dataset since every batch is different\n",
    "builder.evaluate_model(quantized_model, train_dataset, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGh7CR3rWsmL"
   },
   "outputs": [],
   "source": [
    "# quantized_model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLL-pRG4W1f9"
   },
   "outputs": [],
   "source": [
    "l2_reg_fn = kd_utils.get_l2_loss_fn(l2_reg=1e-5, model=quantized_model)\n",
    "quantized_model.add_loss(l2_reg_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "G9ICnzZcW8cn",
    "outputId": "8b0fd261-b823-4591-bf89-8d3caea27b8c"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_2=0.995)\n",
    "quantized_model.compile(optimizer, **builder.get_model_compile_args())\n",
    "quantized_model.fit(prepared_train_dataset, epochs=5, steps_per_epoch=500)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001, beta_2=0.995)\n",
    "quantized_model.compile(optimizer, **builder.get_model_compile_args())\n",
    "quantized_model.fit(prepared_train_dataset, epochs=2, steps_per_epoch=500)\n",
    "\n",
    "quantized_model.save_weights(\"models/quantized-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i-bfHTuyXCVJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BadxD3yRYd2W"
   },
   "outputs": [],
   "source": [
    "quantized_model.load_weights(\"models/quantized-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "chDvqgHBYgIM",
    "outputId": "1f193c8c-9df8-45dd-a3a4-07c11d53bc7b"
   },
   "outputs": [],
   "source": [
    "# features, labels = next(iter(prepared_train_dataset))\n",
    "draw_predictions(quantized_model, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Obb5WPIWY5Qr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "OSQsJ5g9Y8JT",
    "outputId": "93db8f84-1ce3-446e-a40c-2e429528ddc7"
   },
   "outputs": [],
   "source": [
    "builder.evaluate_model(quantized_model, train_dataset, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iDL3lO8XZzQQ",
    "outputId": "d72b75ff-c715-441e-b625-07eea2f49abd"
   },
   "outputs": [],
   "source": [
    "# creates one TFLite version of the model:  \n",
    "#  - models/quantized-model.tflite\n",
    "\n",
    "exported_model, quantized_tflite_models_paths = builder.convert_to_tflite(    \n",
    "    quantized_model, \n",
    "    save_path=\"models/quantized-model.tflite\", \n",
    "    export_batch_size = 1,\n",
    "    raw_dataset = dataset,  # dataset to the test the stats between \n",
    "    num_dataset_samples = 64, # representative dataset number of samples, used when convert_quantized_model is True\n",
    "    num_test_steps = 16, # number of images used to test output statistics\n",
    "    merge_feature_maps=True,  # merge FPN feature maps into single tensor of shape [1, num_anchors, num_outputs]\n",
    "    postprocess_outputs=True,  # apply post processing on head outputs e.g. decode box coordinates to [height, width, y_center, x_center]\n",
    "    convert_quantized_model=False # full integer quantization  does not work with QAT models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9iAPy6TTelV9"
   },
   "source": [
    "# Benchmark models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vHw7cfmfgMU7"
   },
   "outputs": [],
   "source": [
    "import keras_detection.evaluation.detection_metrics as det_metrics\n",
    "from keras_detection.ops.python_ops import map_nested_dict\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QDw9dTEeaP-"
   },
   "outputs": [],
   "source": [
    "all_tflite_paths = [\n",
    "  ('Keras', False ,'models/non-quantized-model.h5'), # Keras model\n",
    "  ('Keras => TFLite', False ,'models/non-quantized-model.tflite'), # from Keras model\n",
    "  ('Keras => TFLite (Post Quantized)', False ,'models/non-quantized-model.quantized.tflite'), # full post train quantization from Keras model\n",
    "  ('Keras QAT => TFLite', False ,'models/quantized-model.tflite'), # from QAT model\n",
    "  ('Keras QAT', True ,'models/quantized-model.h5') # a keras model \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "Nml5SEHFaA2U",
    "outputId": "320a87bf-2fae-482c-d78c-b199ae61df4b"
   },
   "outputs": [],
   "source": [
    "name, is_quantized, path = all_tflite_paths[0]\n",
    "box_detector = builder.as_box_detector(path, is_quantized=is_quantized, iou_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "colab_type": "code",
    "id": "-uBm9LkPdt5X",
    "outputId": "949b41f6-b97a-46cc-fb1f-10a4c3de6500"
   },
   "outputs": [],
   "source": [
    "# Test on single prediction\n",
    "train_dataset_iterator = iter(train_dataset)\n",
    "batch_data = map_nested_dict(next(train_dataset_iterator), lambda x: x.numpy())\n",
    "idx = 0\n",
    "image_data = ImageData.from_dict(batch_data)\n",
    "predictions = box_detector.predict(image_data.features.image)\n",
    "predictions[idx].draw(image=image_data.features.image[idx], fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOm1qVIZm1eN"
   },
   "source": [
    "## Collecting metrics for few batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "ziGoJAkud-_r",
    "outputId": "8ee03384-4f49-418b-eadb-3d47ea482fe7"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def benchmark_models(\n",
    "    models_paths,\n",
    "    num_batches_to_test = 1,\n",
    "    iou_threshold = 0.5, # used for compuing metrics\n",
    "):\n",
    "\n",
    "  test_models = {\n",
    "    name: builder.as_box_detector(path, is_quantized=is_quant, iou_threshold=0.5) \n",
    "    for name, is_quant, path in models_paths\n",
    "  }\n",
    "\n",
    "  test_models_metrics = defaultdict(list)\n",
    "\n",
    "  print(f\"Test models: {test_models.keys()}\")\n",
    "\n",
    "  for i in range(num_batches_to_test):\n",
    "    print(\"Testing batch: \", i)\n",
    "    batch_data = map_nested_dict(next(train_dataset_iterator), lambda x: x.numpy())\n",
    "    image_data = ImageData.from_dict(batch_data)\n",
    "\n",
    "    for k, predictor in test_models.items():\n",
    "      print(f\" => Predicting: {k}\")\n",
    "      predictions_per_image = predictor.predict(image_data.features.image)\n",
    "      targets_per_image = image_data.labels.unbatch()\n",
    "      \n",
    "      metrics = []\n",
    "      for target, predicted in zip(targets_per_image, predictions_per_image):\n",
    "        metrics += det_metrics.image_precision_recall_metrics(\n",
    "            target=target.replace(weights=None), predicted=predicted.to_labels_frame(), \n",
    "            iou_threshold=iou_threshold\n",
    "        )\n",
    "      test_models_metrics[k] += metrics\n",
    "  return test_models_metrics\n",
    "\n",
    "\n",
    "benchmark_metrics = benchmark_models(all_tflite_paths, num_batches_to_test=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "1l2I8mExfa9F",
    "outputId": "d48b9981-067f-42ed-c04b-048c1627c562"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = defaultdict(list)\n",
    "for model_name, metrics in benchmark_metrics.items():\n",
    "  for m in det_metrics.aggregate_metrics(metrics):\n",
    "    data[m.name].append(m.value)\n",
    "  data[\"model\"].append(model_name)\n",
    "\n",
    "pd.DataFrame(data).set_index(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R62cE5GJclcm"
   },
   "source": [
    "# Train Quantized model for short time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "VQFu7837lW8q",
    "outputId": "c2fe239d-8b18-4ee4-f6d5-e4f1f433abcd"
   },
   "outputs": [],
   "source": [
    "quantized_model = builder.build_quantized(\n",
    "    batch_size=None, \n",
    "    non_quantized_model_weights=\"models/non-quantized-model.h5\" # initialize weight from previous model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "piwSVSywcorV",
    "outputId": "0da245f0-2e7f-4081-be56-c702cb4e869e"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_2=0.995)\n",
    "quantized_model.compile(optimizer, **builder.get_model_compile_args())\n",
    "quantized_model.fit(prepared_train_dataset, epochs=1, steps_per_epoch=100)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001, beta_2=0.995)\n",
    "quantized_model.compile(optimizer, **builder.get_model_compile_args())\n",
    "quantized_model.fit(prepared_train_dataset, epochs=1, steps_per_epoch=100)\n",
    "\n",
    "quantized_model.save_weights(\"models/quantized-model-short-train.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bff2u-B_dW8h",
    "outputId": "37039d15-d3dc-416b-d005-842fa6027076"
   },
   "outputs": [],
   "source": [
    "exported_model, quantized_tflite_models_paths = builder.convert_to_tflite(    \n",
    "    quantized_model, \n",
    "    save_path=\"models/quantized-model-short-train.tflite\", \n",
    "    export_batch_size = 1,\n",
    "    raw_dataset = dataset,  # dataset to the test the stats between \n",
    "    num_dataset_samples = 64, # representative dataset number of samples, used when convert_quantized_model is True\n",
    "    num_test_steps = 16, # number of images used to test output statistics\n",
    "    merge_feature_maps=True,  # merge FPN feature maps into single tensor of shape [1, num_anchors, num_outputs]\n",
    "    postprocess_outputs=True,  # apply post processing on head outputs e.g. decode box coordinates to [height, width, y_center, x_center]\n",
    "    convert_quantized_model=False # full integer quantization  does not work with QAT models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONrisnDjc_h2"
   },
   "source": [
    "# Benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SYz59ANhc3yG",
    "outputId": "ee63ecc7-8c59-43d3-deb8-fb06fb21f503"
   },
   "outputs": [],
   "source": [
    "all_tflite_paths_with_short = all_tflite_paths + [\n",
    "  ('Keras QAT => TFLite (short)', False ,'models/quantized-model-short-train.tflite'),\n",
    "  ('Keras QAT (short)', True ,'models/quantized-model-short-train.h5')\n",
    "]\n",
    "benchmark_metrics = benchmark_models(all_tflite_paths_with_short, num_batches_to_test=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "GR8ulx-id4wC",
    "outputId": "8180220c-a398-42cc-c6fb-8093d7e02e24"
   },
   "outputs": [],
   "source": [
    "data = defaultdict(list)\n",
    "for model_name, metrics in benchmark_metrics.items():\n",
    "  for m in det_metrics.aggregate_metrics(metrics):\n",
    "    data[m.name].append(m.value)\n",
    "  data[\"model\"].append(model_name)\n",
    "\n",
    "pd.DataFrame(data).set_index(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wlZeOCWvecIq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "fpn_builder_random_rectangles.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow-2.0",
   "language": "python",
   "name": "tensorflow-2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
