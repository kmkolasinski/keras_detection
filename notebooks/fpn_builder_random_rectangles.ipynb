{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_detection.models.box_detector import BoxDetectionOutput\n",
    "import keras_detection.datasets.datasets_ops as datasets_ops\n",
    "import keras_detection.datasets.random_rectangles as random_rects\n",
    "from keras_detection import ImageData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets_ops.from_numpy_generator(\n",
    "    random_rects.create_random_rectangles_dataset_generator(min_max_num_boxes=(5, 20))\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark dataset sampling\n",
    "# %timeit next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = ImageData.from_dict(next(iter(dataset)))\n",
    "image_frame_data = BoxDetectionOutput.from_tf_boxes(\n",
    "    boxes=image_data.labels.boxes.numpy(),\n",
    "    labels=image_data.labels.labels.numpy()\n",
    ")\n",
    "image_frame_data.draw(image_data.features.image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_detection.datasets.datasets_ops as datasets_ops\n",
    "\n",
    "def aug_fn(image_data: ImageData) -> ImageData:\n",
    "    image = tf.cast(image_data.features.image, tf.float32)\n",
    "    image = tf.image.random_brightness(image, max_delta=1.2)\n",
    "    return image_data.replace_image(image)\n",
    "\n",
    "\n",
    "image_dim = 224\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 1 # we don't have to shuffle random rectangles dataset\n",
    "num_classes = 9 # random rectangles have 9 classes\n",
    "num_parallel_calls = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets_ops.from_numpy_generator(\n",
    "    random_rects.create_random_rectangles_dataset_generator(min_max_num_boxes=(5, 20))\n",
    ")\n",
    "\n",
    "train_dataset = datasets_ops.prepare_dataset(\n",
    "    dataset,\n",
    "    model_image_size=(image_dim, image_dim),\n",
    "    augmentation_fn=aug_fn,\n",
    "    num_epochs=-1,\n",
    "    batch_size=batch_size ,\n",
    "    shuffle_buffer_size=shuffle_buffer_size,\n",
    "    prefetch_buffer_size=4,\n",
    "    num_parallel_calls=num_parallel_calls\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_detection import FPNBuilder\n",
    "from keras_detection.tasks import standard_tasks\n",
    "from keras_detection.backbones import resnet\n",
    "from keras_detection.utils import plotting\n",
    "\n",
    "\n",
    "backbone = resnet.ResNetBackbone(\n",
    "    input_shape=(image_dim, image_dim, 3),\n",
    "    units_per_block=(1, 1, 1),\n",
    "    num_last_blocks=2, # number of feature pyramids\n",
    ")\n",
    "\n",
    "tasks = [\n",
    "    # predicts objectnes score for each anchor\n",
    "    standard_tasks.get_objectness_task(label_smoothing=0.02, obj_class=\"center_ignore_margin\"),\n",
    "    # predicts [height, with, y_center, x_center] location of the box\n",
    "    standard_tasks.get_box_shape_task(\"box_shape\"),\n",
    "    # predicts [num_classes] for each anchor (focal loss is not supported yet)\n",
    "    standard_tasks.get_multiclass_task(num_classes, fl_gamma=0.0, label_smoothing=0, activation='softmax'),\n",
    "]\n",
    "\n",
    "builder = FPNBuilder(backbone=backbone, tasks=tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_train_dataset = train_dataset.map(builder.get_build_training_targets_fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(iter(prepared_train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = \"fm28x28\"\n",
    "\n",
    "targets = [labels[n][..., :-1] for n in builder.get_outputs_names()]\n",
    "targets = builder.predictions_to_dict(targets, postprocess=True)\n",
    "\n",
    "idx = 0\n",
    "target=dict(\n",
    "    objectness=targets[f'{fm}/objectness'][idx],\n",
    "    boxes_shape_map=targets[f'{fm}/box_shape'][idx],\n",
    "    classes_map=targets[f'{fm}/classes'][idx],\n",
    ")\n",
    "\n",
    "render = plotting.draw_compares(    \n",
    "    target=target,\n",
    "    predicted=None,\n",
    "    all_targets=True,\n",
    "    draw_fns=[\n",
    "        plotting.draw_boxes, \n",
    "        plotting.draw_classes_map,\n",
    "        plotting.draw_objectness_map,\n",
    "        plotting.draw_classes_max_score_map,\n",
    "    ],\n",
    "    image=features['image'][idx] / 255,\n",
    "    score_threshold=0.2, \n",
    ")\n",
    "render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_detection.models.utils as kd_utils\n",
    "\n",
    "l2_reg_fn = kd_utils.get_l2_loss_fn(l2_reg=1e-5, model=model)\n",
    "model.add_loss(l2_reg_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_2=0.995)\n",
    "model.compile(optimizer, **builder.get_model_compile_args())\n",
    "model.fit(prepared_train_dataset, epochs=1, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.0",
   "language": "python",
   "name": "tensorflow-2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
